{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Experiment Template\n",
        "\n",
        "**Team Member:** [Your Name]  \n",
        "**Model:** [e.g., RNN, LSTM, GRU, Logistic Regression]  \n",
        "**Embedding:** [e.g., TF-IDF, Word2Vec (Skip-gram), GloVe]\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup & Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "import nltk\n",
        "import os\n",
        "from collections import Counter\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from wordcloud import WordCloud\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Download NLTK data\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "except LookupError:\n",
        "    nltk.download('punkt')\n",
        "try:\n",
        "    nltk.data.find('corpora/stopwords')\n",
        "except LookupError:\n",
        "    nltk.download('stopwords')\n",
        "\n",
        "# Set plot style\n",
        "sns.set(style=\"whitegrid\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "DATA_PATH = '../data/IMDB Dataset.csv'\n",
        "if not os.path.exists(DATA_PATH):\n",
        "    print(f\"Warning: {DATA_PATH} not found. Please ensure the dataset is in the data folder.\")\n",
        "else:\n",
        "    df = pd.read_csv(DATA_PATH)\n",
        "    print(f\"Dataset loaded successfully: {df.shape}\")\n",
        "    display(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Exploratory Data Analysis (EDA)\n",
        "Understanding the dataset characteristics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if 'sentiment' in df.columns:\n",
        "    # Class Distribution\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.countplot(x='sentiment', data=df)\n",
        "    plt.title('Class Distribution')\n",
        "    plt.show()\n",
        "    print(df['sentiment'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Review Length Analysis\n",
        "df['word_count'] = df['review'].apply(lambda x: len(x.split()))\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(df['word_count'], bins=50, kde=True)\n",
        "plt.title('Review Length Distribution (Word Count)')\n",
        "plt.xlabel('Number of Words')\n",
        "plt.show()\n",
        "\n",
        "print(f\"Average word count: {df['word_count'].mean():.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Preprocessing\n",
        "Applying shared preprocessing strategy:\n",
        "1. Lowercase\n",
        "2. Remove HTML tags\n",
        "3. Remove special characters\n",
        "4. Tokenize\n",
        "5. Remove stopwords (Optional based on embedding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def clean_text(text, remove_stopwords=True):\n",
        "    # 1. Lowercase\n",
        "    text = text.lower()\n",
        "    # 2. HTML tag removal\n",
        "    text = re.sub(r'<.*?>', '', text)\n",
        "    # 3. Remove non-alphanumeric characters (preserving spaces)\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "    # 4. Tokenize\n",
        "    tokens = word_tokenize(text)\n",
        "    \n",
        "    # 5. Remove stopwords (Optional based on embedding)\n",
        "    if remove_stopwords:\n",
        "        stop_words = set(stopwords.words('english'))\n",
        "        filtered_tokens = [w for w in tokens if w not in stop_words]\n",
        "        return \" \".join(filtered_tokens)\n",
        "    else:\n",
        "        return \" \".join(tokens)\n",
        "\n",
        "# Apply cleaning (Default strategy)\n",
        "print(\"Preprocessing data (this may take a moment)...\")\n",
        "df['cleaned_review'] = df['review'].apply(lambda x: clean_text(x, remove_stopwords=True))\n",
        "display(df[['review', 'cleaned_review']].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Post-Preprocessing Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Word Cloud for cleaned text\n",
        "all_text = \" \".join(df['cleaned_review'])\n",
        "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(all_text)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.title('Word Cloud (Cleaned Data)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train/Test Split\n",
        "X = df['cleaned_review'].values\n",
        "y = df['sentiment'].apply(lambda x: 1 if x == 'positive' else 0).values # Binary encoding\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "print(f\"Training samples: {len(X_train)}\")\n",
        "print(f\"Testing samples: {len(X_test)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Embedding Layer\n",
        "Implement your specific embedding here (TF-IDF, Word2Vec, GloVe, etc.)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Implement Embedding\n",
        "# Example for Word2Vec/Glove: Prepare Tokenizer and Embedding Matrix\n",
        "# Example for TF-IDF: Use TfidfVectorizer\n",
        "\n",
        "pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Model Architecture\n",
        "Define your model (RNN, LSTM, GRU, or Traditional ML)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Define Model\n",
        "model = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Train model\n",
        "# history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Evaluate\n",
        "# y_pred = model.predict(X_test)\n",
        "# y_pred_class = (y_pred > 0.5).astype(int)\n",
        "\n",
        "# print(\"Accuracy:\", accuracy_score(y_test, y_pred_class))\n",
        "# print(classification_report(y_test, y_pred_class))\n",
        "\n",
        "# Confusion Matrix\n",
        "# cm = confusion_matrix(y_test, y_pred_class)\n",
        "# sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "# plt.xlabel('Predicted')\n",
        "# plt.ylabel('True')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Save Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# results = {\n",
        "#     'model': 'MyModel',\n",
        "#     'embedding': 'MyEmbedding',\n",
        "#     'accuracy': 0.0\n",
        "# }\n",
        "# result_df = pd.DataFrame([results])\n",
        "# result_df.to_csv('../results/experiment_results.csv', mode='a', header=not os.path.exists('../results/experiment_results.csv'), index=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
